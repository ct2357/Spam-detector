{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>../data/000/004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label             path\n",
       "0   ham  ../data/000/000\n",
       "1   ham  ../data/000/001\n",
       "2   ham  ../data/000/002\n",
       "3   ham  ../data/000/003\n",
       "4   ham  ../data/000/004"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=pd.read_csv('.\\\\trec05p-1\\\\full\\\\index',sep=' ',header=None)\n",
    "file_path.columns=['label','path']\n",
    "file_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92189, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                        spam\n",
       "path     ./trec05p-1/data/000/105\n",
       "Name: 105, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path['path']='./trec05p-1'+file_path['path'].str[2:]\n",
    "file_path.iloc[105,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.parser\n",
    "import email.message\n",
    "from email.message import MIMEPart\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(columns=['email_id','parts','attachments','html','subject','body','links','spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done.\n",
      "1000 done.\n",
      "2000 done.\n",
      "3000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.thestreet.com/_yahoo/funds/chrisedmonds/1496696.html\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://iuwEm.ekbeehjkda.info/?9oHKbq9jKdgyX99datPU\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://abNF.wewervnxbf.info/?JsLOfudTihk6_ddJtFb\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.rothers.com/rng/search_results.asp?mscssid=R14S8CXSPE0T8KU32WCA5W9XS8QD8C87\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 done.\n",
      "8000 done.\n",
      "9000 done.\n",
      "10000 done.\n",
      "11000 done.\n",
      "12000 done.\n",
      "13000 done.\n",
      "14000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.cdc.noaa.gov/USclimate/USclimdivs.html\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 done.\n",
      "16000 done.\n",
      "17000 done.\n",
      "18000 done.\n",
      "19000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.lafghanistan.com/laflist.asp\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 done.\n",
      "21000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://runneth-yale.padalai.net/prime/burn/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://hprod.cscbooker.com/BookerController\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://rac.enron.com/RMC/Riskmovie/FlashMenu/FlashMenuFrame.asp\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000 done.\n",
      "24000 done.\n",
      "25000 done.\n",
      "26000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.liquidgeneration.com/poptoons/kill_osama.asp\n",
      "\n",
      "http://www.paratroopers.org/wwtgraphics.htm\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.mnftiu.cc/mnftiu.cc/war.html\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27000 done.\n",
      "28000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://inet.ees.enron.com/vision/comm/marketcentral/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.fema.gov/nfip/1001cnge.pdf\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 done.\n",
      "31000 done.\n",
      "32000 done.\n",
      "33000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://quote.bloomberg.com/fgcgi.cgi?T=marketsquote99_news.ht&s=AO92gchaXRW5yb24g\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://qaro.ticklwvwl.biz/\n",
      "\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://cbs.marketwatch.com/tools/quotes/newsarticle.asp?guid={9184EF70-CADF-43E7-8752-910AECA53741}&siteid=mktw&dist=mah\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000 done.\n",
      "36000 done.\n",
      "37000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.marketwatch.com/news/story.asp?print=1&guid={9490A893-4795-4A61-9B4B-268C6F0C34DC}&siteid=yhoo\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://biz.yahoo.com/t/e/ene.html\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.chron.com/cs/CDA/story.hts/business/1133446\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.universalsavings.com/asp/Login.asp\n",
      "\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.foxnews.com/story/0,2933,38884,00.html\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 done.\n",
      "41000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://cbs.marketwatch.com/tools/quotes/newsarticle.asp?siteid=mktw&sid=1803&guid=%7BD30031DE%2DD722%2D47CE%2D9DF5%2DDE78EDA9C21D%7D\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.oddtodd.com/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.house.gov/commerce_democrats/press/107ltr101.htm\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.theadvocate.com/sports/story.asp?StoryID=16767\n",
      "http://www.nola.com/lsu/t-p/football/index.ssf?/lsustory/lsufoot20.html\n",
      "http://www.nola.com/lsu/t-p/football/index.ssf?/lsustory/lsunotes21.html\n",
      "http://www.tigerdroppings.com/arkansas_game.htm\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43000 done.\n",
      "44000 done.\n",
      "45000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.cnn.com/CNN/Programs/moneyline/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.1400smith.com/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47000 done.\n",
      "48000 done.\n",
      "49000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.phazer.org/samuel.html\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 done.\n",
      "51000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.ferguslex.com/holidaycard/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52000 done.\n",
      "53000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.1400smith.com\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 done.\n",
      "55000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://crosswords.about.com/library/features/dailyxwd/wed/blxwdwed.htm\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000 done.\n",
      "57000 done.\n",
      "58000 done.\n",
      "59000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.nysb.uscourts.gov/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://energycommerce.house.gov/107/news/layletter.pdf\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61000 done.\n",
      "62000 done.\n",
      "63000 done.\n",
      "64000 done.\n",
      "65000 done.\n",
      "66000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://enron:vortmax@www.earthsat.com/misc/enron/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://ubsintegration.corp.enron.com/\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67000 done.\n",
      "68000 done.\n",
      "69000 done.\n",
      "70000 done.\n",
      "71000 done.\n",
      "72000 done.\n",
      "73000 done.\n",
      "74000 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://o-oku-channel.com/naka/\n",
      "\n",
      "���[�������������������B\n",
      "paulresis@yahoo.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\taoxijia\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://o-oku-channel.com/naka/\n",
      "\n",
      "���[�������������������B\n",
      "paulresis@yahoo.com\n",
      "\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 done.\n",
      "76000 done.\n",
      "77000 done.\n",
      "78000 done.\n",
      "79000 done.\n",
      "80000 done.\n",
      "81000 done.\n",
      "82000 done.\n",
      "83000 done.\n",
      "84000 done.\n",
      "85000 done.\n",
      "86000 done.\n",
      "87000 done.\n",
      "88000 done.\n",
      "89000 done.\n",
      "90000 done.\n",
      "91000 done.\n",
      "92000 done.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(file_path)):\n",
    "#for i in range(1,80):\n",
    "    if i%1000==0:\n",
    "        print(\"{} done.\".format(i))\n",
    "    \n",
    "    try:\n",
    "        with open (file_path['path'][i], 'rb') as f:\n",
    "            spam=file_path['label'][i]\n",
    "            email_id=file_path['path'][i][-7:]\n",
    "            m = email.parser.BytesParser().parse(f)\n",
    "            subject=m['subject']\n",
    "            attachments=MIMEPart(m).is_attachment()\n",
    "            parts=0\n",
    "            html=0\n",
    "            parts=0\n",
    "            body=[]\n",
    "            links=[]\n",
    "            if m.is_multipart():\n",
    "                for part in m.walk():\n",
    "                    parts=parts+1\n",
    "                    if part.get_content_type()=='text/html':\n",
    "                        html=1\n",
    "                        soup = BeautifulSoup(part.get_payload(), 'lxml')\n",
    "                        body.append(soup.text)\n",
    "                        links.append(soup.find_all('a'))\n",
    "            else:\n",
    "                body=m.get_payload()\n",
    "                soup = BeautifulSoup(body)\n",
    "                links.append(soup.find_all('a'))\n",
    "                \n",
    "            data.loc[data.shape[0],:]=[email_id,parts,attachments,html,subject.encode(),body,len(links),spam]\n",
    "            #print([email_id,parts,attachments,html,subject.encode(),body,len(links),spam])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>parts</th>\n",
       "      <th>attachments</th>\n",
       "      <th>html</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>links</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91693</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91694</th>\n",
       "      <td>000/001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NGX failover plan.'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91695</th>\n",
       "      <td>000/002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'RE: Intranet Site'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91696</th>\n",
       "      <td>000/003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: ENA Upstream Company information'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91697</th>\n",
       "      <td>000/004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'New Master Physical'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91698</th>\n",
       "      <td>000/005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: ENA Upstream Company/Mirant GISB'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91699</th>\n",
       "      <td>000/006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'PG&amp;E GT-NW Receives Open Season Requests Tot...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91700</th>\n",
       "      <td>000/007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Internet Advertising agreement'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91701</th>\n",
       "      <td>000/008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: Internet Advertising agreement'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91702</th>\n",
       "      <td>000/009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FMPA Oil Invoice'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91703</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91704</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91705</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>User ID:  enrondlr\\nPW:        bnaweb22\\n\\n\\n ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91706</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>User ID:  enrondlr\\nPW:        bnaweb22\\n\\n\\n ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91707</th>\n",
       "      <td>000/001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NGX failover plan.'</td>\n",
       "      <td>\\nHi Chris,  \\n\\nTonight we are rolling out a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91708</th>\n",
       "      <td>000/002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'RE: Intranet Site'</td>\n",
       "      <td>Rika r these new?\\n\\n -----Original Message---...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91709</th>\n",
       "      <td>000/003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: ENA Upstream Company information'</td>\n",
       "      <td>John/Gerald,\\n\\nWe are currently trading under...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91710</th>\n",
       "      <td>000/004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'New Master Physical'</td>\n",
       "      <td>Gerald and Stacy -\\n\\nAttached is a worksheet ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91711</th>\n",
       "      <td>000/005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: ENA Upstream Company/Mirant GISB'</td>\n",
       "      <td>FYI. Below is a copy of my communication with ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91712</th>\n",
       "      <td>000/006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'PG&amp;E GT-NW Receives Open Season Requests Tot...</td>\n",
       "      <td>PG&amp;E GT-NW Plans Lateral Across Washington Sta...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      email_id  parts attachments  html  \\\n",
       "91693  000/000    0.0       False   0.0   \n",
       "91694  000/001    0.0       False   0.0   \n",
       "91695  000/002    0.0       False   0.0   \n",
       "91696  000/003    0.0       False   0.0   \n",
       "91697  000/004    0.0       False   0.0   \n",
       "91698  000/005    0.0       False   0.0   \n",
       "91699  000/006    0.0       False   0.0   \n",
       "91700  000/007    0.0       False   0.0   \n",
       "91701  000/008    0.0       False   0.0   \n",
       "91702  000/009    0.0       False   0.0   \n",
       "91703  000/000    0.0       False   0.0   \n",
       "91704  000/000    0.0       False   0.0   \n",
       "91705  000/000    0.0       False   0.0   \n",
       "91706  000/000    0.0       False   0.0   \n",
       "91707  000/001    0.0       False   0.0   \n",
       "91708  000/002    0.0       False   0.0   \n",
       "91709  000/003    0.0       False   0.0   \n",
       "91710  000/004    0.0       False   0.0   \n",
       "91711  000/005    0.0       False   0.0   \n",
       "91712  000/006    0.0       False   0.0   \n",
       "\n",
       "                                                 subject  \\\n",
       "91693     b'FW: June 29 -- BNA, Inc. Daily Labor Report'   \n",
       "91694                              b'NGX failover plan.'   \n",
       "91695                               b'RE: Intranet Site'   \n",
       "91696            b'FW: ENA Upstream Company information'   \n",
       "91697                             b'New Master Physical'   \n",
       "91698            b'FW: ENA Upstream Company/Mirant GISB'   \n",
       "91699  b'PG&E GT-NW Receives Open Season Requests Tot...   \n",
       "91700                  b'Internet Advertising agreement'   \n",
       "91701              b'FW: Internet Advertising agreement'   \n",
       "91702                                b'FMPA Oil Invoice'   \n",
       "91703     b'FW: June 29 -- BNA, Inc. Daily Labor Report'   \n",
       "91704     b'FW: June 29 -- BNA, Inc. Daily Labor Report'   \n",
       "91705     b'FW: June 29 -- BNA, Inc. Daily Labor Report'   \n",
       "91706     b'FW: June 29 -- BNA, Inc. Daily Labor Report'   \n",
       "91707                              b'NGX failover plan.'   \n",
       "91708                               b'RE: Intranet Site'   \n",
       "91709            b'FW: ENA Upstream Company information'   \n",
       "91710                             b'New Master Physical'   \n",
       "91711            b'FW: ENA Upstream Company/Mirant GISB'   \n",
       "91712  b'PG&E GT-NW Receives Open Season Requests Tot...   \n",
       "\n",
       "                                                    body  links spam  \n",
       "91693                                                 []    0.0  ham  \n",
       "91694                                                 []    0.0  ham  \n",
       "91695                                                 []    0.0  ham  \n",
       "91696                                                 []    0.0  ham  \n",
       "91697                                                 []    0.0  ham  \n",
       "91698                                                 []    0.0  ham  \n",
       "91699                                                 []    0.0  ham  \n",
       "91700                                                 []    0.0  ham  \n",
       "91701                                                 []    0.0  ham  \n",
       "91702                                                 []    0.0  ham  \n",
       "91703                                                 []    0.0  ham  \n",
       "91704                                                 []    0.0  ham  \n",
       "91705  User ID:  enrondlr\\nPW:        bnaweb22\\n\\n\\n ...    0.0  ham  \n",
       "91706  User ID:  enrondlr\\nPW:        bnaweb22\\n\\n\\n ...    1.0  ham  \n",
       "91707  \\nHi Chris,  \\n\\nTonight we are rolling out a ...    1.0  ham  \n",
       "91708  Rika r these new?\\n\\n -----Original Message---...    1.0  ham  \n",
       "91709  John/Gerald,\\n\\nWe are currently trading under...    1.0  ham  \n",
       "91710  Gerald and Stacy -\\n\\nAttached is a worksheet ...    1.0  ham  \n",
       "91711  FYI. Below is a copy of my communication with ...    1.0  ham  \n",
       "91712  PG&E GT-NW Plans Lateral Across Washington Sta...    1.0  ham  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open('datanew2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pickle.load(open('datanew2.p', 'rb')) #the original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joinstr(data2.loc[91705,'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91692, 8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>parts</th>\n",
       "      <th>attachments</th>\n",
       "      <th>html</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>links</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91693</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91694</th>\n",
       "      <td>000/001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NGX failover plan.'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91695</th>\n",
       "      <td>000/002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'RE: Intranet Site'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91696</th>\n",
       "      <td>000/003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'FW: ENA Upstream Company information'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91697</th>\n",
       "      <td>000/004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'New Master Physical'</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      email_id  parts attachments  html  \\\n",
       "91693  000/000    0.0       False   0.0   \n",
       "91694  000/001    0.0       False   0.0   \n",
       "91695  000/002    0.0       False   0.0   \n",
       "91696  000/003    0.0       False   0.0   \n",
       "91697  000/004    0.0       False   0.0   \n",
       "\n",
       "                                              subject body  links  spam  \n",
       "91693  b'FW: June 29 -- BNA, Inc. Daily Labor Report'   []    0.0     0  \n",
       "91694                           b'NGX failover plan.'   []    0.0     0  \n",
       "91695                            b'RE: Intranet Site'   []    0.0     0  \n",
       "91696         b'FW: ENA Upstream Company information'   []    0.0     0  \n",
       "91697                          b'New Master Physical'   []    0.0     0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spam']=data['spam'].replace({'ham':0,'spam':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email_id        object\n",
       "parts          float64\n",
       "attachments     object\n",
       "html           float64\n",
       "subject         object\n",
       "body            object\n",
       "links          float64\n",
       "spam             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email_id       object\n",
       "parts           int32\n",
       "attachments     int32\n",
       "html            int32\n",
       "subject        object\n",
       "body           object\n",
       "links           int32\n",
       "spam            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['parts','attachments','html','links']]=data[['parts','attachments','html','links']].astype('int32')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinstr(x):\n",
    "    if isinstance(x,list):\n",
    "        if len(x)!=0:\n",
    "            return ' '.join(x)\n",
    "        else:\n",
    "            return 'emptystring'\n",
    "    elif isinstance(x,str):\n",
    "        return x\n",
    "    else:\n",
    "        return \"NA\"\n",
    "def check_str(x):\n",
    "    return type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body']=data['body'].apply(joinstr).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>parts</th>\n",
       "      <th>attachments</th>\n",
       "      <th>html</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>links</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [email_id, parts, attachments, html, subject, body, links, spam]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['body']=='NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>parts</th>\n",
       "      <th>attachments</th>\n",
       "      <th>html</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>links</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91706</th>\n",
       "      <td>000/000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'FW: June 29 -- BNA, Inc. Daily Labor Report'</td>\n",
       "      <td>User ID:  enrondlr\\nPW:        bnaweb22\\n\\n\\n ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91707</th>\n",
       "      <td>000/001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'NGX failover plan.'</td>\n",
       "      <td>\\nHi Chris,  \\n\\nTonight we are rolling out a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91708</th>\n",
       "      <td>000/002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'RE: Intranet Site'</td>\n",
       "      <td>Rika r these new?\\n\\n -----Original Message---...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91709</th>\n",
       "      <td>000/003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'FW: ENA Upstream Company information'</td>\n",
       "      <td>John/Gerald,\\n\\nWe are currently trading under...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91710</th>\n",
       "      <td>000/004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'New Master Physical'</td>\n",
       "      <td>Gerald and Stacy -\\n\\nAttached is a worksheet ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91711</th>\n",
       "      <td>000/005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'FW: ENA Upstream Company/Mirant GISB'</td>\n",
       "      <td>FYI. Below is a copy of my communication with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91712</th>\n",
       "      <td>000/006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'PG&amp;E GT-NW Receives Open Season Requests Tot...</td>\n",
       "      <td>PG&amp;E GT-NW Plans Lateral Across Washington Sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91713</th>\n",
       "      <td>000/007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Internet Advertising agreement'</td>\n",
       "      <td>Mark -- I am working with the East power desk ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91714</th>\n",
       "      <td>000/008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'FW: Internet Advertising agreement'</td>\n",
       "      <td>oops.  here it is.\\n\\nkal\\n \\n\\n\\n\\n -----Orig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91715</th>\n",
       "      <td>000/009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'FMPA Oil Invoice'</td>\n",
       "      <td>Mark and Charlie,\\n\\nFMPA is ready to bill us ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      email_id  parts  attachments  html  \\\n",
       "91706  000/000      0            0     0   \n",
       "91707  000/001      0            0     0   \n",
       "91708  000/002      0            0     0   \n",
       "91709  000/003      0            0     0   \n",
       "91710  000/004      0            0     0   \n",
       "91711  000/005      0            0     0   \n",
       "91712  000/006      0            0     0   \n",
       "91713  000/007      0            0     0   \n",
       "91714  000/008      0            0     0   \n",
       "91715  000/009      0            0     0   \n",
       "\n",
       "                                                 subject  \\\n",
       "91706     b'FW: June 29 -- BNA, Inc. Daily Labor Report'   \n",
       "91707                              b'NGX failover plan.'   \n",
       "91708                               b'RE: Intranet Site'   \n",
       "91709            b'FW: ENA Upstream Company information'   \n",
       "91710                             b'New Master Physical'   \n",
       "91711            b'FW: ENA Upstream Company/Mirant GISB'   \n",
       "91712  b'PG&E GT-NW Receives Open Season Requests Tot...   \n",
       "91713                  b'Internet Advertising agreement'   \n",
       "91714              b'FW: Internet Advertising agreement'   \n",
       "91715                                b'FMPA Oil Invoice'   \n",
       "\n",
       "                                                    body  links  spam  \n",
       "91706  User ID:  enrondlr\\nPW:        bnaweb22\\n\\n\\n ...      1     0  \n",
       "91707  \\nHi Chris,  \\n\\nTonight we are rolling out a ...      1     0  \n",
       "91708  Rika r these new?\\n\\n -----Original Message---...      1     0  \n",
       "91709  John/Gerald,\\n\\nWe are currently trading under...      1     0  \n",
       "91710  Gerald and Stacy -\\n\\nAttached is a worksheet ...      1     0  \n",
       "91711  FYI. Below is a copy of my communication with ...      1     0  \n",
       "91712  PG&E GT-NW Plans Lateral Across Washington Sta...      1     0  \n",
       "91713  Mark -- I am working with the East power desk ...      1     0  \n",
       "91714  oops.  here it is.\\n\\nkal\\n \\n\\n\\n\\n -----Orig...      1     0  \n",
       "91715  Mark and Charlie,\\n\\nFMPA is ready to bill us ...      1     0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"email_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open('data_new2_ready.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pickle.load(open('data_new_ready.p', 'rb'))\n",
    "# data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Train Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test= train_test_split(data, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77938, 8), (13754, 8))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape,data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_train, open('train.p', 'wb'))\n",
    "pickle.dump(data_test, open('test.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train= pickle.load(open('train.p', 'rb'))\n",
    "# data_test= pickle.load(open('test.p', 'rb'))\n",
    "# data_train.shape,data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Text Predictors: Bag-of-Word Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference https://machinelearningmastery.com/deep-learning-bag-of-words-model-sentiment-analysis/\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trial in a small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           b'FW: June 29 -- BNA, Inc. Daily Labor Report'\n",
       "1                                    b'NGX failover plan.'\n",
       "2                                     b'RE: Intranet Site'\n",
       "3                  b'FW: ENA Upstream Company information'\n",
       "4                                   b'New Master Physical'\n",
       "                               ...                        \n",
       "91687    b'=?gb2312?B?c2hvZXMgZnJvbSB3d3cubG92ZWluZmFza...\n",
       "91688    b'=?gb2312?B?c2hvZXMgZnJvbSB3d3cubG92ZWluZmFza...\n",
       "91689    b'=?gb2312?B?c2hvZXMgZnJvbSB3d3cubG92ZWluZmFza...\n",
       "91690    b'=?gb2312?B?c2hvZXMgZnJvbSB3d3cubG92ZWluZmFza...\n",
       "91691    b'=?gb2312?B?c2hvZXMgZnJvbSB3d3cubG92ZWluZmFza...\n",
       "Name: subject, Length: 91692, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=data['subject']\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trial=X_train[:5].copy()\n",
    "#X_train_trial[1]=['iii','ddd']\n",
    "#X_train_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVectorizer=CountVectorizer(input=\"content\",stop_words=stopwords.words(\"english\"))\n",
    "X=countVectorizer.fit_transform(X_train_trial)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29',\n",
       " 'bna',\n",
       " 'company',\n",
       " 'daily',\n",
       " 'ena',\n",
       " 'fw',\n",
       " 'inc',\n",
       " 'information',\n",
       " 'intranet',\n",
       " 'june',\n",
       " 'labor',\n",
       " 'master',\n",
       " 'new',\n",
       " 'one',\n",
       " 'physical',\n",
       " 'report',\n",
       " 'site',\n",
       " 'upstream']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_text(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'\\d+', '', text)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_countVectorizer(X):\n",
    "    countVectorizer=CountVectorizer(input=\"content\",stop_words=stopwords.words(\"english\"))\n",
    "    X=countVectorizer.fit_transform(X)\n",
    "    return X,countVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_train,v_subject=build_countVectorizer(data_train['subject'])\n",
    "subject_test=v_subject.transform(data_test['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train,v_body=build_countVectorizer(data_train['body'])\n",
    "body_test=v_body.transform(data_test['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77938, 39634), (13754, 39634), (77938, 408571), (13754, 408571))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_train.shape,subject_test.shape,body_train.shape,body_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_feature.p',\"wb\") as f:\n",
    "    pickle.dump(subject_train, f)\n",
    "    pickle.dump(subject_test, f)\n",
    "    pickle.dump(v_subject, f)\n",
    "    pickle.dump(body_train, f)\n",
    "    pickle.dump(body_test, f)\n",
    "    pickle.dump(v_body, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
